\documentclass[11pt, american, draft]{PhdThesis}

\usepackage[american]{babel}
\usepackage[final]{graphicx}

\usepackage[T1]{fontenc}
\usepackage{enumitem}
\usepackage{forest}
\usepackage{url}

\forestset{
  default preamble = {
    for tree = {draw, ellipse}
  }
}

\author{Matteo Morena}
\email{morena.matteo@gmail.com}
\supervisor{Marco Comini}
\title{Implementation of an interpreter with graphical interface of a simple imperative language}
\date{2021--2022}

\begin{document}
  \pagestyle{empty}
  \maketitle

  % \begin{dedication}
  %   TBD
  % \end{dedication}

  % \begin{abstract}
  %   TBD
  % \end{abstract}

  % \begin{acknowledgments}
  %   TBD
  % \end{acknowledgments}

  \frontmatter
  \partstyle{serifbig}
  \chaptertitlestyle{serifbig}
  \pagestyle{serif}
  \tableofcontents
  % \listoffigures
  % \listoftables

  % \introduction
  % TBD

  % \section*{an intro section}
  % TBD

  \mainmatter

  % \chapter{Preliminaries}
  % TBD

  % \section{a preliminaries section}
  % TBD

  \part{Conceptual overview}

  \chapter{Parsing}

  The first phase of any compiler or interpreter is called \emph{parsing}. The purpose of this
  phase is to analyze an input string and determine if it conforms to some set of rules; if it
  does, a logical representation of the input is constructed.

  \section{Languages and grammars}

  Consider a parser for arithmetic expressions. The input of the parser is any sequence of
  characters. Invalid strings like \texttt{(1 +)} and \texttt{(3 * * 4)} get rejected. Valid
  strings like \texttt{(2 * (3 + 4))} get accepted.

  The \emph{language} accepted by a parser is the set of all possible inputs which the parser may
  accept. The set of rules to which the input has to conform to is called the \emph{grammar} of the
  language.

  As an example, we could define the grammar for arithmetic expressions as follows:

  \begin{itemize}[noitemsep,topsep=0pt]
    \item A sequence of characters representing a number is a \emph{literal expression}.

    \item If $x$ is an expression, then \texttt{(}, followed by $x$, followed by \texttt{)} is a
          \emph{parenthesized expression}.

    \item If $x$ is a literal or parenthesized expression, then $x$, preceded by a unary operator,
          is a \emph{unary expression}. An unary operator is one of the following
          characters: \texttt{+}, \texttt{-}.

    \item If $x$ and $y$ are unary or parenthesized expressions, then $x$, followed by a
          multiplicative operator, followed by $y$, is a \emph{multiplicative expression}. A
          multiplicative operator is one of the following characters: \texttt{*}, \texttt{/}.

    \item If $x$ and $y$ are multiplicative or parenthesized expressions, then $x$, followed by an
          additive operator, followed by $y$, is an \emph{additive expression}. An additive operator
          is one of the following characters: \texttt{+}, \texttt{-}.
  \end{itemize}

  According to such rules, the string \texttt{(2 * (3 + 4))} is a valid arithmetic expression. By
  definition:

  \begin{itemize}[noitemsep,topsep=0pt]
    \item \texttt{2}, \texttt{3} and \texttt{4} are literals;
    \item \texttt{3 + 4} is an additive expression;
    \item \texttt{(3 + 4)} is a parenthesized expression;
    \item \texttt{2 * (3 + 4)} is a multiplicative expression;
    \item \texttt{(2 * (3 + 4))} is an expression.
  \end{itemize}

  \section{Syntax trees}

  A \emph{syntax tree} is the representation of a string accepted by the parser; this data
  structure stores the syntactic structure of the input.

  A syntax tree may retain all information necessary to reconstruct the input; in this case, it is
  called a \emph{concrete} syntax tree. If some information about the source is discarded
  (comments, for example), it is called an \emph{abstract} syntax tree.

  Consider the language of arithmetic expressions: we can think of at least two possible syntax
  trees for the string \texttt{(2 + 3 * (4 + 5))}, depending on how much information has been kept.
  When information is thrown away, the semantic meaning stays the same: for instance, details about
  parenthesization can be discarded if the resulting syntax tree still represents the same order of
  operations.

  \begin{figure}
    \centering

    \begin{ttfamily}
      \begin{forest}[+ [2] [* [3] [+ [4] [5]]]]\end{forest}
      \begin{forest}[( ) [+ [2] [* [3] [( ) [+ [4] [5]]]]]]\end{forest}
    \end{ttfamily}

    \caption{Two semantically equivalent syntax trees for \texttt{(2 + 3 * (4 + 5))}}
  \end{figure}

  As we'll see later, the parser for Devin uses a single tree representation which retains enough
  information for syntax highlighting, but also discards whitespace. For our purposes, the
  distinction between abstract and concrete syntax tree isn't necessary: for this reason, from now
  on I'll just use the term \emph{syntax tree}.

  \section{Parser combinators}

  There are many ways to recognize some input and generate an associated syntax tree. There has been
  much academic research, and it is trivial to find so-called \emph{parser generators}: these are
  tools which, given a grammar, automatically generate code for parsing the language in question.
  Such tools build upon well-known algorithms, such as LL, LR, LALR, just to throw a few names
  around. These tools are great and very performant; however, they're kind of magical.

  In this section, we'll see how there's no fundamental need for any generators; although such tools
  are handy, it isn't actually that difficult to write a parser from scratch, using a technique
  called \emph{recursive descent parsing}. Recursive descent parsers are used by the GCC compiler
  and the V8 JavaScript engines, for example\cite{nystrom}.

  Recursive descent is a method of constructing a parser using a collection of recursive functions.
  The simplest functions parse the atoms (or \emph{tokens}) of the target language; examples of such
  functions are parsers for numbers and identifiers. By gluing together simpler functions, more
  complex parsers can be created: for example, a parser for two-dimensional coordinates
  \texttt{($x$, $y$)} can be built by using the parsers for open-parenthesis, number, comma, number,
  and close-parenthesis respectively. Finally, parsers can be combined recursively: a parser $P$
  could depend on a parser $Q$, which in turn depends on $P$. Consider any language supporting
  \texttt{while} statements: the body of the \texttt{while} is yet another statement, which in turn
  could be a \texttt{while} statement.

  Recursive descent can be implemented in any imperative language; of course, a similar technique
  can be applied to functional programming as well. The functional approach lends itself perfectly
  for this kind of task; in particular, higher order functions abstract the boilerplate necessary to
  glue together different parsing functions. These higher order functions are called \emph{parser
  combinators}, as they combine simpler parsers into more complex ones.

  The general interface employed by parser combinators is that of a function which takes some input
  string; the function returns either an error or some result together with the remaining input. For
  instance, applying the function parsing an integer on the input string \texttt{21*2} yields the
  pair $\left(21, \texttt{*2}\right)$.

  Some common parser combinators are:

  \begin{itemize}[noitemsep,topsep=0pt]
    \item The \emph{sequence combinator}. Informally, this combinator runs two parsers in succession
          and combines their results.

          Let $P$ and $Q$ be two parsers. The sequence combinator runs $P$; if it succeeds, then $Q$
          is run on the remaining input. If $Q$ also succeeds, the combinator succeeds with the
          combined results of $P$ and $Q$. If $P$ or $Q$ fail, then the combinator also fails.

    \item The \emph{alternative combinator}. Informally, this combinator implements choice.

          Let $P$ and $Q$ be two parsers. The alternative combinator runs $P$ and $Q$ on the same
          input. If $P$ succeeds, the combinator succeeds with the same result as $P$ did; if $Q$
          succeeds, the combinator succeeds with the same result as $Q$ did. If both $P$ and $Q$
          fail, then the combinator also fails.

    \item The \emph{option combinator}. Informally, this combinator runs a parser zero or one time.

          Let $P$ be a parser. The option combinator tries to run $P$. If $P$ succeeds, the
          combinator succeeds with the same result as $P$ did. If $P$ fails, the combinator succeeds
          with an empty result.

    \item The \emph{repetition combinator}. Informally, this combinator runs a parser many times.

          Let $P$ be a parser. The repetition combinator tries to run $P$ as many times as possible,
          until $P$ fails. Each time $P$ succeeds, the remaining input is fed back into the next
          application of $P$ itself. This combinator succeeds with the accumulated results of all
          successful runs.

    \item The \emph{bind combinator}. Informally, this combinator allows one parser to depend on the
          result of another parser. As we will see, this is the most powerful combinator of them
          all. All others could be expressed in terms of the bind combinator.

          Let $P$ be a parser and $f$ a one-parameter function yielding
          another parser. The bind combinator tries to run $P$; if it succeeds, it applies $f$ on
          the result of $P$, running the resulting parser on the remaining input. If $P$ fails, this
          combinator also fails.
  \end{itemize}

  \chapter{Tree traversal}

  Once a syntax tree has been constructed by the parser, the tree can be traversed in a multitude of
  ways. In general, syntax trees can not only represent the structure of a programming languages,
  but also the structure of markup languages or other kinds of structured languages. For the
  purposes of this thesis, I'll discuss the processing of programming languages only.

  It is important to note the grammar of a language only describes its \emph{syntax}: on its own,
  it only defines which inputs strings are valid, and which are not. Similarly, a parser only
  transforms syntactically valid input strings into trees: it is the role of other components to
  give \emph{semantic meaning} to such trees.

  \begin{itemize}[noitemsep,topsep=0pt]
    \item An \emph{evaluator} would associate the nodes of a syntax tree with actions to execute.
          Examples of such actions are performing arithmetic calculations, conditionally executing
          other nodes, and assigning or retrieving values from variables.

    \item A \emph{compiler} would translate a syntax tree into some other form. For instance, the
          GCC compiler produces object files from valid C syntax; in turn, object files can be
          parsed by the system's linker, which translates a collection of such files into a runnable
          executable.

    \item On languages where the semantics involve static types, a \emph{type checker} would verify
          that no type errors would be produced by evaluation or compilation. In such systems, the
          type checker coexists with an evaluator or compiler (or both); it is fundamental that all
          components obey to the same semantics. Often, the evaluator or compiler depends on some
          additional information provided by the type checker: this won't be the case for Devin.

    \item Similarly to type checking, a \emph{linter} would analyze the syntax tree as well.
          Contrary to the type checking, the linter may not depend on static types (if any);
          furthermore, successful compilation or execution doesn't depend on linting. Rather, the
          linter suggests how the original source could be improved. Like with the type checker, all
          components must obey to the same semantics.

    \item A \emph{syntax highlighter} would use the information stored in a syntax tree to perform
          syntax highlighting. Such a syntax tree would be rather concrete, as each node would be
          associated with a position in the parser's input string.
  \end{itemize}

  \section{Evaluation}

  \section{Type checking}

  \section{Syntax highlighting}

  \chapter{The monadic interface}



  \backmatter

  % \conclusions
  % TBD

  % \appendix

  % \chapter{Some technicalities}
  % TBD

  % \section{a section}
  % TBD

  \backmatter

  \bibliographystyle{plain}
  \bibliography{biblio}

  % \printindex  % use makeindex to generate the index
\end{document}
